{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c22dd883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milvus connected: False\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections, utility\n",
    "\n",
    "# Connect to Milvus\n",
    "connections.connect(alias=\"default\", host=\"localhost\", port=\"19530\")\n",
    "\n",
    "# Check connection\n",
    "print(\"Milvus connected:\", utility.has_collection(\"test_collection\"))  # Should return False initially\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19f405b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milvus connected: True\n",
      "Collections: ['pdf_chunks', 'hybrid_collection', 'demo_collection']\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections, utility\n",
    "\n",
    "# Connect to Milvus\n",
    "connections.connect(alias=\"default\", host=\"localhost\", port=\"19530\")\n",
    "\n",
    "# Actually check the connection\n",
    "print(\"Milvus connected:\", connections.has_connection(\"default\"))\n",
    "\n",
    "# Optional: list existing collections\n",
    "print(\"Collections:\", utility.list_collections())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "527704df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranavsing\\AppData\\Local\\Temp\\ipykernel_17164\\3094177873.py:22: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.llms.fake import FakeListLLM\n",
    "\n",
    "# Set your OpenAI key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "# Define the prompt template\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"What is the capital of {country}?\"\n",
    ")\n",
    "\n",
    "# Create an LLM instance\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Use the parser to get string output\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Chain everything together\n",
    "chain = template | llm | parser\n",
    "\n",
    "# Call the chain\n",
    "response = chain.invoke({\"country\": \"France\"})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c193565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Tell me a joke about cats')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "\n",
    "prompt_template.invoke({\"topic\": \"cats\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0a0612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.llms.fake import FakeListLLM  \n",
    "\n",
    "\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=\"What is the capital of {country}?\"\n",
    ")\n",
    "\n",
    "\n",
    "fake_llm = FakeListLLM(responses=[\"Paris\"]) \n",
    "\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "\n",
    "chain = template | fake_llm | parser\n",
    "\n",
    "response = chain.invoke({\"country\": \"France\"})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3c6982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "chat_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8c4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"You are a master branding consultant who specializes in naming brands. You come up with catchy and memorable names for brands.\n",
    "\n",
    "Take thhe  brand description below delimited by triple backticks and come up with catchy names for the brand.\n",
    "\n",
    "brand description: ```{brand_description}```\n",
    "then based on the description and you hot new brand name give the brand a score 1-10 for how likely it is to succeed.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68e99348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dea22391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['brand_description'], input_types={}, partial_variables={}, template='You are a master branding consultant who specializes in naming brands. You come up with catchy and memorable names for brands.\\n\\nTake thhe  brand description below delimited by triple backticks and come up with catchy names for the brand.\\n\\nbrand description: ```{brand_description}```\\nthen based on the description and you hot new brand name give the brand a score 1-10 for how likely it is to succeed.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "197e6a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "branding_messages = prompt_template.format_messages(brand_description=\"a cool hip new sneaker brand aimed at rich kids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfedec62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='You are a master branding consultant who specializes in naming brands. You come up with catchy and memorable names for brands.\\n\\nTake thhe  brand description below delimited by triple backticks and come up with catchy names for the brand.\\n\\nbrand description: ```a cool hip new sneaker brand aimed at rich kids```\\nthen based on the description and you hot new brand name give the brand a score 1-10 for how likely it is to succeed.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branding_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7559fe30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranavsing\\AppData\\Local\\Temp\\ipykernel_3540\\1991233728.py:1: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  consultant_response = chat_llm(branding_messages)\n"
     ]
    }
   ],
   "source": [
    "consultant_response = chat_llm(branding_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6bbc373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand name: LuxKicks\n",
      "\n",
      "Likelihood of success: 8/10\n"
     ]
    }
   ],
   "source": [
    "print(consultant_response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
